# /workspace/yolo/ultralytics/cfg/models/new/yolov12-sod-fusion-v5-E6.yaml
# 作用: 这是为 E6 消融实验定制的 YOLOv5-simple 模型配置。
# E6 目标: 在 E5 的基础上，加入 A2_Attn 注意力模块。
# 与 E5 的区别: 在 backbone 的特定位置重新加入了 A2_Attn。
# 与完整模型的区别: 仅缺少 CA_Block。

nc: 10  # 类别数量 (VisDrone 数据集有 10 类)
depth_multiple: 0.33
width_multiple: 0.50
ch: 3   # 输入通道

# E6 主干网络 (Backbone) - 保留 SE, CBAM, Swin, 和 A2_Attn
backbone:
  # Stage 1
  - [ -1, 1, Conv, [64, 3, 2] ]             # 0: stride 2 conv -> P1/2
  - [ -1, 1, SE_Block, [64] ]               # 1: E6: KEPT SE attention
  - [ -1, 1, Conv, [128, 3, 2] ]            # 2: -> P2/4
  - [ -1, 3, C2f, [128, True] ]             # 3: CSP block (Backbone P2 output)
  - [ -1, 1, CBAM_Block, [128, 16] ]        # 4: E6: KEPT CBAM attention
  - [ -1, 1, Conv, [256, 3, 2] ]            # 5: -> P3/8
  - [ -1, 6, C2f, [256, True] ]             # 6: CSP block (Backbone P3 output)
  - [ -1, 1, Conv, [512, 3, 2] ]            # 7: -> P4/16
  - [ -1, 3, C2f, [512, True] ]             # 8: CSP block
  - [ -1, 1, SwinBlock, [4, 7] ]            # 9: E6: KEPT Swin Transformer (Backbone P4 output)
  - [ -1, 1, Conv, [1024, 3, 2] ]           # 10: -> P5/32
  - [ -1, 2, C2f, [1024, True] ]            # 11: CSP block
  - [ -1, 1, A2_Attn, [8, 8] ]              # 12: E6: KEPT Area Attention (A2)
  - [ -1, 1, SPPF, [1024, 5] ]              # 13: SPPF (Backbone P5 output)

# E6 颈部网络 (Neck) - 仅移除了 CA_Block
neck:
  # Top-Down path (PANet)
  # P5 -> P4
  - [ -1, 1, Conv, [512, 1, 1] ]                 # 14: reduce channel
  - [ -1, 1, nn.Upsample, [None, 2, 'nearest'] ]  # 15: upsample
  - [ [ -1, 9 ], 1, Concat, [1] ]                 # 16: concat P5 upsampled with P4 from backbone (layer 9)
  - [ -1, 3, C2f, [512, True] ]                   # 17: fusion at P4
  - [ -1, 1, CBAM_Block, [512, 16] ]              # 18: E6: KEPT CBAM attention
  
  # P4 -> P3
  - [ -1, 1, Conv, [256, 1, 1] ]                 # 19: reduce channel
  - [ -1, 1, nn.Upsample, [None, 2, 'nearest'] ]  # 20: upsample
  - [ [ -1, 6 ], 1, Concat, [1] ]                 # 21: concat with P3 from backbone (layer 6)
  - [ -1, 3, C2f, [256, True] ]                   # 22: fusion at P3
  - [ -1, 1, SE_Block, [256] ]                    # 23: E6: KEPT SE attention
  
  # P3 -> P2
  - [ -1, 1, Conv, [128, 1, 1] ]                 # 24: reduce channel
  - [ -1, 1, nn.Upsample, [None, 2, 'nearest'] ]  # 25: upsample
  - [ [ -1, 3 ], 1, Concat, [1] ]                 # 26: concat with P2 from backbone (layer 3)
  - [ -1, 3, C2f, [128, True] ]                   # 27: fusion at P2
  - [ -1, 1, SwinBlock, [2, 7] ]                  # 28: E6: KEPT Swin Transformer (P2 head output)

  # Bottom-Up path
  # P2 -> P3
  - [ 28, 1, Conv, [256, 3, 2] ]                  # 29: downsample P2->P3, input from P2 fusion (layer 28)
  - [ [ -1, 23 ], 1, Concat, [1] ]                # 30: concat with P3 from top-down path (layer 23)
  - [ -1, 3, C2f, [256, True] ]                   # 31: fusion at P3 (P3 head output)
  # - [ -1, 1, CA_Block, [256] ]                  # E6: REMOVED

  # P3 -> P4
  - [ -1, 1, Conv, [512, 3, 2] ]                  # 32: downsample P3->P4
  - [ [ -1, 18 ], 1, Concat, [1] ]                # 33: concat with P4 from top-down path (layer 18)
  - [ -1, 3, C2f, [512, True] ]                   # 34: fusion at P4 (P4 head output)

  # P4 -> P5
  - [ -1, 1, Conv, [1024, 3, 2] ]                 # 35: downsample P4->P5
  - [ [ -1, 13 ], 1, Concat, [1] ]                # 36: concat with P5 from backbone (layer 13, after SPPF)
  - [ -1, 2, C2f, [1024, True] ]                  # 37: fusion at P5 (P5 head output)

# E6 检测头 (Head) - 使用 P2, P3, P4, P5 四个尺度的输出
head:
  - [ [28, 31, 34, 37], 1, Detect, [nc] ] # Detect from P2(28), P3(31), P4(34), P5(37)